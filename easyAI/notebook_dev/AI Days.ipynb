{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "030d5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cb49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing data - to make sure methods work\n",
    "data_diabetes = pd.read_csv('datasets/diabetes.csv')\n",
    "data_movies = pd.read_csv('datasets/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb7e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diabetes_np = np.array(data_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35b22dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diabetes.iloc[:,0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb0eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(data_diabetes.iloc[:,0].dtype == 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b489a75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diabetes_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84fb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "2c162491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn-binary-classifier-model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_0 (Dense)      (None, 8)                 72        \n",
      "                                                                 \n",
      " hidden_layer_1 (Dense)      (None, 6)                 54        \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 5)                 35        \n",
      "                                                                 \n",
      " hidden_layer_3 (Dense)      (None, 4)                 24        \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 190\n",
      "Trainable params: 190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 2ms/step - loss: 14243.8379 - accuracy: 0.0000e+00 - val_loss: 14091.5117 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 13634.5352 - accuracy: 0.0000e+00 - val_loss: 12756.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 10685.1504 - accuracy: 0.0000e+00 - val_loss: 7906.2373 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 4946.6660 - accuracy: 0.0000e+00 - val_loss: 2625.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1668.2405 - accuracy: 0.0000e+00 - val_loss: 1007.9927 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 849.4308 - accuracy: 0.0000e+00 - val_loss: 665.7042 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 629.3245 - accuracy: 0.0000e+00 - val_loss: 536.9848 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 523.7268 - accuracy: 0.0000e+00 - val_loss: 460.3998 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 456.2337 - accuracy: 0.0000e+00 - val_loss: 407.3860 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 406.3329 - accuracy: 0.0000e+00 - val_loss: 366.3860 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 365.9767 - accuracy: 0.0000e+00 - val_loss: 330.6967 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 330.8126 - accuracy: 0.0000e+00 - val_loss: 298.8122 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 298.3973 - accuracy: 0.0000e+00 - val_loss: 269.3944 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 269.3117 - accuracy: 0.0000e+00 - val_loss: 243.1113 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 242.7192 - accuracy: 0.0000e+00 - val_loss: 218.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 218.0181 - accuracy: 0.0000e+00 - val_loss: 194.4654 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 194.4812 - accuracy: 0.0000e+00 - val_loss: 171.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 170.5239 - accuracy: 0.0000e+00 - val_loss: 147.7537 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 146.0188 - accuracy: 0.0000e+00 - val_loss: 124.6500 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 124.5071 - accuracy: 0.0000e+00 - val_loss: 106.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 107.4520 - accuracy: 0.0000e+00 - val_loss: 91.9028 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 93.5212 - accuracy: 0.0000e+00 - val_loss: 79.6232 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 81.3279 - accuracy: 0.0000e+00 - val_loss: 68.8685 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 70.8772 - accuracy: 0.0000e+00 - val_loss: 59.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 61.8063 - accuracy: 0.0000e+00 - val_loss: 51.8586 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 53.7480 - accuracy: 0.0000e+00 - val_loss: 44.7176 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 46.8329 - accuracy: 0.0000e+00 - val_loss: 38.7777 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 40.7526 - accuracy: 0.0000e+00 - val_loss: 33.5602 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 35.6506 - accuracy: 0.0000e+00 - val_loss: 29.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 31.1832 - accuracy: 0.0000e+00 - val_loss: 25.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 27.3468 - accuracy: 0.0000e+00 - val_loss: 22.0395 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 24.0314 - accuracy: 0.0000e+00 - val_loss: 19.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 21.1749 - accuracy: 0.0000e+00 - val_loss: 16.9306 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 18.5968 - accuracy: 0.0000e+00 - val_loss: 14.8896 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 16.3153 - accuracy: 0.0000e+00 - val_loss: 12.9830 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 14.5512 - accuracy: 0.0000e+00 - val_loss: 11.4589 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 12.8775 - accuracy: 0.0000e+00 - val_loss: 10.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 11.3799 - accuracy: 0.0000e+00 - val_loss: 9.1005 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 10.1484 - accuracy: 0.0000e+00 - val_loss: 7.9623 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 9.0720 - accuracy: 0.0000e+00 - val_loss: 7.2520 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 8.1663 - accuracy: 0.0000e+00 - val_loss: 6.3694 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 7.2381 - accuracy: 0.0000e+00 - val_loss: 5.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 6.4855 - accuracy: 0.0000e+00 - val_loss: 5.0832 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 5.8168 - accuracy: 0.0000e+00 - val_loss: 4.4635 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 5.1726 - accuracy: 0.0000e+00 - val_loss: 4.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 4.6555 - accuracy: 0.0000e+00 - val_loss: 3.6534 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 4.1349 - accuracy: 0.0000e+00 - val_loss: 3.2589 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.7408 - accuracy: 0.0000e+00 - val_loss: 2.9928 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.3986 - accuracy: 0.0000e+00 - val_loss: 2.6789 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.0387 - accuracy: 0.0000e+00 - val_loss: 2.4948 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.7610 - accuracy: 0.0000e+00 - val_loss: 2.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.4783 - accuracy: 0.0000e+00 - val_loss: 1.9987 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.2496 - accuracy: 0.0000e+00 - val_loss: 1.8092 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.0479 - accuracy: 0.0000e+00 - val_loss: 1.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.8362 - accuracy: 0.0000e+00 - val_loss: 1.5019 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.6646 - accuracy: 0.0000e+00 - val_loss: 1.3541 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.4944 - accuracy: 0.0000e+00 - val_loss: 1.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.3903 - accuracy: 0.0000e+00 - val_loss: 1.1472 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.2460 - accuracy: 0.0000e+00 - val_loss: 0.9988 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.1289 - accuracy: 0.0000e+00 - val_loss: 0.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.0489 - accuracy: 0.0000e+00 - val_loss: 0.8272 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.9199 - accuracy: 0.0000e+00 - val_loss: 0.7608 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.8728 - accuracy: 0.0000e+00 - val_loss: 0.6857 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.7673 - accuracy: 0.0000e+00 - val_loss: 0.6291 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.0000e+00 - val_loss: 0.5670 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.0000e+00 - val_loss: 0.5143 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.0000e+00 - val_loss: 0.4631 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.0000e+00 - val_loss: 0.4970 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.0000e+00 - val_loss: 0.3951 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.0000e+00 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.0000e+00 - val_loss: 0.3228 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.0000e+00 - val_loss: 0.2850 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.0000e+00 - val_loss: 0.2577 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.0000e+00 - val_loss: 0.2374 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.0000e+00 - val_loss: 0.2260 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.0000e+00 - val_loss: 0.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.0000e+00 - val_loss: 0.1987 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.0000e+00 - val_loss: 0.1786 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.0000e+00 - val_loss: 0.1668 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.0000e+00 - val_loss: 0.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.0000e+00 - val_loss: 0.1509 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.0000e+00 - val_loss: 0.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.0000e+00 - val_loss: 0.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.0000e+00 - val_loss: 0.1293 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1105 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.0000e+00 - val_loss: 0.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.0000e+00 - val_loss: 0.1065 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.0000e+00 - val_loss: 0.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.0000e+00 - val_loss: 0.0905 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.0000e+00 - val_loss: 0.0896 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.0000e+00 - val_loss: 0.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.0000e+00 - val_loss: 0.0774 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.0000e+00 - val_loss: 0.0780 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.0000e+00 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.0000e+00 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.0000e+00 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0000e+00 - val_loss: 0.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.0000e+00 - val_loss: 0.0602 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "obj = create_workspace_object(data_housing, 'regression', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "2cf7870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6215338201655791"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.performance_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "3da98e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn-binary-classifier-model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_0 (Dense)      (None, 9)                 90        \n",
      "                                                                 \n",
      " hidden_layer_1 (Dense)      (None, 7)                 70        \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 6)                 48        \n",
      "                                                                 \n",
      " hidden_layer_3 (Dense)      (None, 5)                 35        \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 255\n",
      "Trainable params: 255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 60ms/step - loss: 0.6830 - categorical_accuracy: 0.6853 - val_loss: 0.6870 - val_categorical_accuracy: 0.6609\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6803 - categorical_accuracy: 0.7244 - val_loss: 0.6843 - val_categorical_accuracy: 0.6957\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6776 - categorical_accuracy: 0.7486 - val_loss: 0.6814 - val_categorical_accuracy: 0.7565\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6747 - categorical_accuracy: 0.7821 - val_loss: 0.6782 - val_categorical_accuracy: 0.7739\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6714 - categorical_accuracy: 0.7989 - val_loss: 0.6747 - val_categorical_accuracy: 0.7739\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6678 - categorical_accuracy: 0.8101 - val_loss: 0.6709 - val_categorical_accuracy: 0.7739\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6638 - categorical_accuracy: 0.8212 - val_loss: 0.6669 - val_categorical_accuracy: 0.7739\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6594 - categorical_accuracy: 0.8287 - val_loss: 0.6625 - val_categorical_accuracy: 0.7739\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6547 - categorical_accuracy: 0.8324 - val_loss: 0.6578 - val_categorical_accuracy: 0.7739\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6495 - categorical_accuracy: 0.8324 - val_loss: 0.6525 - val_categorical_accuracy: 0.7826\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6436 - categorical_accuracy: 0.8343 - val_loss: 0.6466 - val_categorical_accuracy: 0.8087\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6373 - categorical_accuracy: 0.8399 - val_loss: 0.6401 - val_categorical_accuracy: 0.8348\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6304 - categorical_accuracy: 0.8436 - val_loss: 0.6329 - val_categorical_accuracy: 0.8348\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6230 - categorical_accuracy: 0.8510 - val_loss: 0.6252 - val_categorical_accuracy: 0.8435\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6151 - categorical_accuracy: 0.8585 - val_loss: 0.6169 - val_categorical_accuracy: 0.8609\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6061 - categorical_accuracy: 0.8696 - val_loss: 0.6077 - val_categorical_accuracy: 0.8696\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5964 - categorical_accuracy: 0.8734 - val_loss: 0.5978 - val_categorical_accuracy: 0.8870\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5859 - categorical_accuracy: 0.8734 - val_loss: 0.5870 - val_categorical_accuracy: 0.8870\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5744 - categorical_accuracy: 0.8715 - val_loss: 0.5753 - val_categorical_accuracy: 0.8957\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5619 - categorical_accuracy: 0.8790 - val_loss: 0.5629 - val_categorical_accuracy: 0.9043\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5487 - categorical_accuracy: 0.8827 - val_loss: 0.5500 - val_categorical_accuracy: 0.9043\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5345 - categorical_accuracy: 0.8920 - val_loss: 0.5360 - val_categorical_accuracy: 0.9043\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5191 - categorical_accuracy: 0.8957 - val_loss: 0.5207 - val_categorical_accuracy: 0.9130\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5029 - categorical_accuracy: 0.9069 - val_loss: 0.5041 - val_categorical_accuracy: 0.9043\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4855 - categorical_accuracy: 0.9162 - val_loss: 0.4865 - val_categorical_accuracy: 0.9043\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4671 - categorical_accuracy: 0.9181 - val_loss: 0.4674 - val_categorical_accuracy: 0.9043\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4475 - categorical_accuracy: 0.9255 - val_loss: 0.4472 - val_categorical_accuracy: 0.9043\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4270 - categorical_accuracy: 0.9311 - val_loss: 0.4253 - val_categorical_accuracy: 0.9130\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4056 - categorical_accuracy: 0.9348 - val_loss: 0.4028 - val_categorical_accuracy: 0.9304\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3840 - categorical_accuracy: 0.9385 - val_loss: 0.3795 - val_categorical_accuracy: 0.9304\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3620 - categorical_accuracy: 0.9423 - val_loss: 0.3561 - val_categorical_accuracy: 0.9478\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3403 - categorical_accuracy: 0.9441 - val_loss: 0.3330 - val_categorical_accuracy: 0.9565\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3189 - categorical_accuracy: 0.9534 - val_loss: 0.3109 - val_categorical_accuracy: 0.9565\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2983 - categorical_accuracy: 0.9572 - val_loss: 0.2890 - val_categorical_accuracy: 0.9652\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2784 - categorical_accuracy: 0.9609 - val_loss: 0.2680 - val_categorical_accuracy: 0.9652\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2595 - categorical_accuracy: 0.9665 - val_loss: 0.2470 - val_categorical_accuracy: 0.9652\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2414 - categorical_accuracy: 0.9739 - val_loss: 0.2265 - val_categorical_accuracy: 0.9652\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2241 - categorical_accuracy: 0.9739 - val_loss: 0.2072 - val_categorical_accuracy: 0.9739\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2076 - categorical_accuracy: 0.9739 - val_loss: 0.1888 - val_categorical_accuracy: 0.9739\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1919 - categorical_accuracy: 0.9739 - val_loss: 0.1718 - val_categorical_accuracy: 0.9739\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1773 - categorical_accuracy: 0.9739 - val_loss: 0.1560 - val_categorical_accuracy: 0.9739\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1631 - categorical_accuracy: 0.9758 - val_loss: 0.1412 - val_categorical_accuracy: 0.9826\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1502 - categorical_accuracy: 0.9795 - val_loss: 0.1288 - val_categorical_accuracy: 0.9826\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1385 - categorical_accuracy: 0.9795 - val_loss: 0.1177 - val_categorical_accuracy: 0.9826\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1283 - categorical_accuracy: 0.9832 - val_loss: 0.1079 - val_categorical_accuracy: 0.9826\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1181 - categorical_accuracy: 0.9832 - val_loss: 0.0990 - val_categorical_accuracy: 0.9826\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1088 - categorical_accuracy: 0.9851 - val_loss: 0.0914 - val_categorical_accuracy: 0.9826\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1002 - categorical_accuracy: 0.9870 - val_loss: 0.0845 - val_categorical_accuracy: 0.9826\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0925 - categorical_accuracy: 0.9870 - val_loss: 0.0786 - val_categorical_accuracy: 0.9826\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0851 - categorical_accuracy: 0.9870 - val_loss: 0.0734 - val_categorical_accuracy: 0.9826\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0786 - categorical_accuracy: 0.9888 - val_loss: 0.0681 - val_categorical_accuracy: 0.9826\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0714 - categorical_accuracy: 0.9907 - val_loss: 0.0634 - val_categorical_accuracy: 0.9826\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0654 - categorical_accuracy: 0.9907 - val_loss: 0.0589 - val_categorical_accuracy: 0.9826\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0600 - categorical_accuracy: 0.9907 - val_loss: 0.0549 - val_categorical_accuracy: 0.9913\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0546 - categorical_accuracy: 0.9926 - val_loss: 0.0511 - val_categorical_accuracy: 0.9913\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0499 - categorical_accuracy: 0.9926 - val_loss: 0.0478 - val_categorical_accuracy: 0.9913\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0457 - categorical_accuracy: 0.9926 - val_loss: 0.0448 - val_categorical_accuracy: 0.9913\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0420 - categorical_accuracy: 0.9944 - val_loss: 0.0419 - val_categorical_accuracy: 0.9913\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0388 - categorical_accuracy: 0.9944 - val_loss: 0.0393 - val_categorical_accuracy: 0.9913\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0359 - categorical_accuracy: 0.9981 - val_loss: 0.0368 - val_categorical_accuracy: 0.9913\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0334 - categorical_accuracy: 0.9981 - val_loss: 0.0341 - val_categorical_accuracy: 0.9913\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0311 - categorical_accuracy: 0.9981 - val_loss: 0.0319 - val_categorical_accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0289 - categorical_accuracy: 0.9981 - val_loss: 0.0299 - val_categorical_accuracy: 0.9913\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0270 - categorical_accuracy: 0.9981 - val_loss: 0.0280 - val_categorical_accuracy: 0.9913\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0252 - categorical_accuracy: 0.9981 - val_loss: 0.0264 - val_categorical_accuracy: 0.9913\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0236 - categorical_accuracy: 0.9981 - val_loss: 0.0249 - val_categorical_accuracy: 0.9913\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0221 - categorical_accuracy: 0.9981 - val_loss: 0.0236 - val_categorical_accuracy: 0.9913\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0208 - categorical_accuracy: 0.9981 - val_loss: 0.0223 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0195 - categorical_accuracy: 0.9981 - val_loss: 0.0212 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0183 - categorical_accuracy: 0.9981 - val_loss: 0.0201 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0173 - categorical_accuracy: 1.0000 - val_loss: 0.0190 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0163 - categorical_accuracy: 1.0000 - val_loss: 0.0181 - val_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0154 - categorical_accuracy: 1.0000 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0146 - categorical_accuracy: 1.0000 - val_loss: 0.0164 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0138 - categorical_accuracy: 1.0000 - val_loss: 0.0157 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0131 - categorical_accuracy: 1.0000 - val_loss: 0.0150 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0125 - categorical_accuracy: 1.0000 - val_loss: 0.0143 - val_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0119 - categorical_accuracy: 1.0000 - val_loss: 0.0137 - val_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0113 - categorical_accuracy: 1.0000 - val_loss: 0.0130 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0108 - categorical_accuracy: 1.0000 - val_loss: 0.0125 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0103 - categorical_accuracy: 1.0000 - val_loss: 0.0120 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0098 - categorical_accuracy: 1.0000 - val_loss: 0.0116 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0094 - categorical_accuracy: 1.0000 - val_loss: 0.0111 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0090 - categorical_accuracy: 1.0000 - val_loss: 0.0107 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0087 - categorical_accuracy: 1.0000 - val_loss: 0.0103 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0083 - categorical_accuracy: 1.0000 - val_loss: 0.0099 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0080 - categorical_accuracy: 1.0000 - val_loss: 0.0096 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0077 - categorical_accuracy: 1.0000 - val_loss: 0.0092 - val_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0074 - categorical_accuracy: 1.0000 - val_loss: 0.0089 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0071 - categorical_accuracy: 1.0000 - val_loss: 0.0085 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0069 - categorical_accuracy: 1.0000 - val_loss: 0.0082 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0066 - categorical_accuracy: 1.0000 - val_loss: 0.0080 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0064 - categorical_accuracy: 1.0000 - val_loss: 0.0077 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0061 - categorical_accuracy: 1.0000 - val_loss: 0.0075 - val_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 0.0073 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0057 - categorical_accuracy: 1.0000 - val_loss: 0.0071 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0056 - categorical_accuracy: 1.0000 - val_loss: 0.0069 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0054 - categorical_accuracy: 1.0000 - val_loss: 0.0067 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 0.0065 - val_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 0.0063 - val_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "obj2 = create_workspace_object(data_diabetes, 'classification', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7266f3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2.performance_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb487c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2d8e6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: dataset, attribute values of all the dropdowns (is image data, orientation of inputted csv)\n",
    "# nn_type can be: 'classification-binary', 'classification-multi', 'regression' (can be extended later)\n",
    "def create_workspace_object(data, nn_type, isIncorrectOrientation):\n",
    "    \n",
    "    # preprocess data method here\n",
    "    targets, data_preprocessed = preprocess_data(data, isIncorrectOrientation)\n",
    "    \n",
    "    # get dataset splits\n",
    "    dataset = train_val_test_split(data_preprocessed, targets, nn_type)\n",
    "    \n",
    "    # generate params\n",
    "    nn_params = generate_nn_params(dataset, nn_type)\n",
    "        \n",
    "    # generate nn model\n",
    "    model = generate_nn_model(dataset, nn_params)\n",
    "    \n",
    "    # train model\n",
    "    model_fitted = train_model(model, dataset)\n",
    "    \n",
    "    # model predictions\n",
    "    preds = predict_model(model_fitted, dataset)\n",
    "    \n",
    "    # eval model\n",
    "    performance_metric = eval_model(preds, dataset, nn_type)\n",
    "    \n",
    "    # create object here\n",
    "    workspace_object = WorkspaceObject(model_fitted, performance_metric)\n",
    "    \n",
    "    # return object (or do whatever needs to be done)\n",
    "    return workspace_object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "245a4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what is going to be stored in S3 to be pulled by the other lambda\n",
    "class WorkspaceObject:\n",
    "    \n",
    "    def __init__(self, model, performance_metric):\n",
    "        self.model = model\n",
    "        self.performance_metric = performance_metric\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035fe39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8dbaf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: will eventually contain functionality to deal with varying data types and types of data\n",
    "def preprocess_data(data_raw, transposed):\n",
    "        \n",
    "    # transposed will be true if each column is a sample instead of each row (just flip it)\n",
    "    if transposed == True:\n",
    "        data_raw = data_raw.T\n",
    "        \n",
    "    # remove target values\n",
    "    targets = data_raw.iloc[:,-1]\n",
    "    data_raw.drop(data_raw.columns[-1], axis=1)\n",
    "        \n",
    "    # nan handling: remove feature if over 40% of column is nan\n",
    "    to_drop = []\n",
    "    for col_name in data_raw:\n",
    "        if data_raw[col_name].isna().sum() / len(data_raw.axes[0]) > .4:\n",
    "            to_drop.append(col_name)\n",
    "        if data_raw[col_name].dtype == 'str' or data_raw[col_name].dtype == 'datetime64':\n",
    "            to_drop.append(col_name)\n",
    "    \n",
    "    data_raw.drop(to_drop, axis=1)\n",
    "    \n",
    "    # nan handling: KNN impute the remaining nans with n_neighbors as a function of the number of\n",
    "    knn_imputer = KNNImputer(n_neighbors=(.05 * len(data_raw.axes[0])), weights='uniform', metric='nan_euclidean')\n",
    "    data_imputed = knn_imputer.fit_transform(data_raw)\n",
    "        \n",
    "    # standardize each column respective to itself (not normalizing because we aren't removing outliers)\n",
    "    data_return = np.copy(data_imputed.T)\n",
    "    for ind, col in enumerate(data_imputed.T):\n",
    "        temp = StandardScaler().fit_transform(col.reshape(-1,1))\n",
    "        data_return[ind] = temp.ravel()\n",
    "        \n",
    "    return np.array(targets), data_return.T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "40157fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(data, targets, nn_type):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(data, targets, test_size=.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=.5, random_state=42)\n",
    "    if nn_type == 'classification':\n",
    "        encoder = OneHotEncoder()\n",
    "        y_train = encoder.fit_transform(copy.deepcopy(y_train).reshape((-1,1))).toarray()\n",
    "        y_val = encoder.fit_transform(copy.deepcopy(y_val).reshape((-1,1))).toarray()\n",
    "        y_test = encoder.fit_transform(copy.deepcopy(y_test).reshape((-1,1))).toarray()\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3fa78c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nn_params(dataset, nn_type):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = dataset\n",
    "    input_shape = X_train.shape[1]\n",
    "    if nn_type == 'classification':\n",
    "        output_shape = len(np.unique(y_train))\n",
    "        output_activation = 'softmax'\n",
    "        hidden_widths = []\n",
    "        in_s = input_shape\n",
    "        while in_s > output_shape + 2:\n",
    "            hidden_widths.append(in_s)\n",
    "            in_s = round(in_s*.8)\n",
    "        \n",
    "        loss = 'categorical_crossentropy'\n",
    "        metric = 'categorical_accuracy'\n",
    "            \n",
    "    elif nn_type == 'regression':\n",
    "        output_shape = 1\n",
    "        output_activation = 'linear'\n",
    "        hidden_widths = []\n",
    "        in_s = input_shape\n",
    "        while in_s > output_shape + 2:\n",
    "            hidden_widths.append(in_s)\n",
    "            in_s = round(in_s*.8)\n",
    "            \n",
    "        loss = 'mse'\n",
    "        metric = 'accuracy'\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        print('Not a currently valid nn_type')\n",
    "        \n",
    "    return (input_shape, hidden_widths, output_shape, output_activation, loss, metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f5dd4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "def generate_nn_model(dataset, nn_params):\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = dataset\n",
    "    \n",
    "    input_shape, hidden_widths, output_shape, output_activation, loss, metric = nn_params\n",
    "    \n",
    "    model = keras.models.Sequential(name=name)\n",
    "    \n",
    "    model.add(keras.Input(shape=(input_shape,), sparse=False))\n",
    "    \n",
    "    for i, width in enumerate(hidden_widths):\n",
    "        model.add(keras.layers.Dense(width, activation='relu', name=f'hidden_layer_{i}'))\n",
    "        \n",
    "    model.add(keras.layers.Dense(output_shape, activation=output_activation, name='output',\n",
    "                                kernel_initializer=keras.initializers.RandomNormal(stddev=np.sqrt(0.1)),\n",
    "                                bias_initializer=keras.initializers.Zeros(), use_bias=True))\n",
    "    \n",
    "    opt = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=opt, metrics=[metric])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "37ebc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def train_model(model, dataset):\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = dataset\n",
    "    \n",
    "    hobj = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=200, shuffle=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5b677033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model, dataset):\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = dataset\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "26941cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(preds, dataset, nn_type):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = dataset\n",
    "    \n",
    "    if nn_type == 'classification':\n",
    "        return accuracy_score(y_test, labelize_softmax(preds))\n",
    "    elif nn_type == 'regression':\n",
    "        return mean_squared_error(y_test, preds)\n",
    "    else:\n",
    "        print(\"not a valid nn_type\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7b5784a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_softmax(preds):\n",
    "    return (preds == preds.max(axis=1)[:,None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "be15aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housing = pd.DataFrame(fetch_california_housing().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b4851684",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_housing = fetch_california_housing().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "504415d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d7d46755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ea051ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = np.concatenate((data_housing, target_housing.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "758d24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(housing).to_csv('housing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c77a9c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1         2         3       4         5      6       7\n",
       "0      8.3252  41.0  6.984127  1.023810   322.0  2.555556  37.88 -122.23\n",
       "1      8.3014  21.0  6.238137  0.971880  2401.0  2.109842  37.86 -122.22\n",
       "2      7.2574  52.0  8.288136  1.073446   496.0  2.802260  37.85 -122.24\n",
       "3      5.6431  52.0  5.817352  1.073059   558.0  2.547945  37.85 -122.25\n",
       "4      3.8462  52.0  6.281853  1.081081   565.0  2.181467  37.85 -122.25\n",
       "...       ...   ...       ...       ...     ...       ...    ...     ...\n",
       "20635  1.5603  25.0  5.045455  1.133333   845.0  2.560606  39.48 -121.09\n",
       "20636  2.5568  18.0  6.114035  1.315789   356.0  3.122807  39.49 -121.21\n",
       "20637  1.7000  17.0  5.205543  1.120092  1007.0  2.325635  39.43 -121.22\n",
       "20638  1.8672  18.0  5.329513  1.171920   741.0  2.123209  39.43 -121.32\n",
       "20639  2.3886  16.0  5.254717  1.162264  1387.0  2.616981  39.37 -121.24\n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9ac88324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_pass = data_diabetes\n",
    "data_to_pass = data_housing\n",
    "nn_type = 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e6385ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, preprocessed_data = preprocess_data(data_to_pass, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f6021fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_val_test_split(preprocessed_data, targets, nn_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1bf603bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = generate_nn_params(dataset, nn_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d740545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn-binary-classifier-model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_0 (Dense)      (None, 8)                 72        \n",
      "                                                                 \n",
      " hidden_layer_1 (Dense)      (None, 6)                 54        \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 5)                 35        \n",
      "                                                                 \n",
      " hidden_layer_3 (Dense)      (None, 4)                 24        \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 190\n",
      "Trainable params: 190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = generate_nn_model(dataset, nn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "49cbce32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 2ms/step - loss: 14297.4189 - accuracy: 0.0000e+00 - val_loss: 14243.4277 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 14214.2715 - accuracy: 0.0000e+00 - val_loss: 14098.9287 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 13978.2461 - accuracy: 0.0000e+00 - val_loss: 13720.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 13266.3320 - accuracy: 0.0000e+00 - val_loss: 12486.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 11121.7773 - accuracy: 0.0000e+00 - val_loss: 9221.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 6990.1904 - accuracy: 0.0000e+00 - val_loss: 4520.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2925.5789 - accuracy: 0.0000e+00 - val_loss: 1572.0549 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1256.5482 - accuracy: 0.0000e+00 - val_loss: 894.4135 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 889.4648 - accuracy: 0.0000e+00 - val_loss: 717.8319 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 738.2902 - accuracy: 0.0000e+00 - val_loss: 610.1660 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 629.3162 - accuracy: 0.0000e+00 - val_loss: 523.5952 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 532.2586 - accuracy: 0.0000e+00 - val_loss: 453.6643 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 454.7305 - accuracy: 0.0000e+00 - val_loss: 395.3156 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 391.1140 - accuracy: 0.0000e+00 - val_loss: 345.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 337.8251 - accuracy: 0.0000e+00 - val_loss: 303.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 292.2855 - accuracy: 0.0000e+00 - val_loss: 264.9662 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 253.0990 - accuracy: 0.0000e+00 - val_loss: 230.8326 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 217.9843 - accuracy: 0.0000e+00 - val_loss: 200.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 187.7014 - accuracy: 0.0000e+00 - val_loss: 172.9830 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 161.6918 - accuracy: 0.0000e+00 - val_loss: 149.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 139.0458 - accuracy: 0.0000e+00 - val_loss: 130.0588 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 120.2369 - accuracy: 0.0000e+00 - val_loss: 113.0287 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 104.4124 - accuracy: 0.0000e+00 - val_loss: 98.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 91.1953 - accuracy: 0.0000e+00 - val_loss: 86.6559 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 80.0997 - accuracy: 0.0000e+00 - val_loss: 76.3025 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 70.5298 - accuracy: 0.0000e+00 - val_loss: 67.5474 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 61.9991 - accuracy: 0.0000e+00 - val_loss: 59.6837 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 54.9823 - accuracy: 0.0000e+00 - val_loss: 53.1434 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 48.6391 - accuracy: 0.0000e+00 - val_loss: 47.3779 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 43.1140 - accuracy: 0.0000e+00 - val_loss: 42.3092 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 38.1418 - accuracy: 0.0000e+00 - val_loss: 37.3631 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 33.4447 - accuracy: 0.0000e+00 - val_loss: 33.0573 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 29.4653 - accuracy: 0.0000e+00 - val_loss: 29.2116 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 26.0670 - accuracy: 0.0000e+00 - val_loss: 25.9806 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 23.0378 - accuracy: 0.0000e+00 - val_loss: 22.8383 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 20.4013 - accuracy: 0.0000e+00 - val_loss: 20.2743 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 18.1964 - accuracy: 0.0000e+00 - val_loss: 18.2472 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 16.4377 - accuracy: 0.0000e+00 - val_loss: 16.3402 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 14.7491 - accuracy: 0.0000e+00 - val_loss: 14.6796 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 13.1312 - accuracy: 0.0000e+00 - val_loss: 13.3495 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 11.7941 - accuracy: 0.0000e+00 - val_loss: 12.0554 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 10.5203 - accuracy: 0.0000e+00 - val_loss: 10.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 9.5783 - accuracy: 0.0000e+00 - val_loss: 9.9620 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 8.8243 - accuracy: 0.0000e+00 - val_loss: 9.1720 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 8.1420 - accuracy: 0.0000e+00 - val_loss: 8.5577 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 7.4683 - accuracy: 0.0000e+00 - val_loss: 7.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 6.9504 - accuracy: 0.0000e+00 - val_loss: 7.3917 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 6.6813 - accuracy: 0.0000e+00 - val_loss: 6.8384 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 6.0741 - accuracy: 0.0000e+00 - val_loss: 6.3831 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 5.7794 - accuracy: 0.0000e+00 - val_loss: 6.0461 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 5.3249 - accuracy: 0.0000e+00 - val_loss: 5.5802 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 4.9418 - accuracy: 0.0000e+00 - val_loss: 5.2288 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 4.7298 - accuracy: 0.0000e+00 - val_loss: 4.8670 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 4.3235 - accuracy: 0.0000e+00 - val_loss: 4.5200 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 4.0675 - accuracy: 0.0000e+00 - val_loss: 4.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.7929 - accuracy: 0.0000e+00 - val_loss: 3.9315 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.5785 - accuracy: 0.0000e+00 - val_loss: 3.6297 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.2811 - accuracy: 0.0000e+00 - val_loss: 3.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.0739 - accuracy: 0.0000e+00 - val_loss: 3.2064 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.9528 - accuracy: 0.0000e+00 - val_loss: 3.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.7884 - accuracy: 0.0000e+00 - val_loss: 2.7789 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.5619 - accuracy: 0.0000e+00 - val_loss: 2.6179 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.3823 - accuracy: 0.0000e+00 - val_loss: 2.5854 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.3322 - accuracy: 0.0000e+00 - val_loss: 2.3012 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.2245 - accuracy: 0.0000e+00 - val_loss: 2.2452 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.0844 - accuracy: 0.0000e+00 - val_loss: 2.0803 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.9822 - accuracy: 0.0000e+00 - val_loss: 2.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.9308 - accuracy: 0.0000e+00 - val_loss: 1.8712 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.7729 - accuracy: 0.0000e+00 - val_loss: 1.7720 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.7038 - accuracy: 0.0000e+00 - val_loss: 1.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.6635 - accuracy: 0.0000e+00 - val_loss: 1.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.6352 - accuracy: 0.0000e+00 - val_loss: 1.5263 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.6086 - accuracy: 0.0000e+00 - val_loss: 1.7901 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.6090 - accuracy: 0.0000e+00 - val_loss: 1.5816 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.4568 - accuracy: 0.0000e+00 - val_loss: 1.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.3518 - accuracy: 0.0000e+00 - val_loss: 1.2678 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.2115 - accuracy: 0.0000e+00 - val_loss: 1.2121 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.1385 - accuracy: 0.0000e+00 - val_loss: 1.1698 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.1403 - accuracy: 0.0000e+00 - val_loss: 1.1276 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.0415 - accuracy: 0.0000e+00 - val_loss: 1.0265 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.0309 - accuracy: 0.0000e+00 - val_loss: 0.9469 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.9213 - accuracy: 0.0000e+00 - val_loss: 0.8728 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.8620 - accuracy: 0.0000e+00 - val_loss: 0.8029 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.7808 - accuracy: 0.0000e+00 - val_loss: 0.7367 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.0000e+00 - val_loss: 0.7776 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.0000e+00 - val_loss: 0.7191 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.0000e+00 - val_loss: 0.6058 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.0000e+00 - val_loss: 0.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.0000e+00 - val_loss: 0.5429 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 0.0000e+00 - val_loss: 0.5584 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.0000e+00 - val_loss: 0.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.0000e+00 - val_loss: 0.4572 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.0000e+00 - val_loss: 0.4362 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.0000e+00 - val_loss: 0.4081 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.0000e+00 - val_loss: 0.3902 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.0000e+00 - val_loss: 0.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.0000e+00 - val_loss: 0.3587 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.0000e+00 - val_loss: 0.3299 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.0000e+00 - val_loss: 0.3287 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_fitted = train_model(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cf6256c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_model(model_fitted, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fefa8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f22e8a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3096,), (3096, 8))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = dataset\n",
    "y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b4530d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096, 1)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c4c81b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_trans = labelize_softmax(preds)\n",
    "preds_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4550d46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096,)\n",
      "(3096, 1)\n",
      "1.949779547346977\n"
     ]
    }
   ],
   "source": [
    "print(eval_model(preds, dataset, nn_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c366c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed103b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ca6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f74131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bed97b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a560dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431d59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c1234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d070e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ad404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cbd8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6ac59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
